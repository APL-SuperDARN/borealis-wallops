{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOOPBACK TESTER\n",
    "\n",
    "This notebook is useful for loopback tests when you have some Borealis data you would like to verify. This notebook is built off of the original test_beamforming.py script that I wrote in Nov/Dec 2018 to verify beamforming algorithms in Borealis. However, these analyses are useful to verify data after any update to the Borealis code. What follows is a list of functions that I plan to build into this script. - Marci Detwiller Feb 2019\n",
    "\n",
    "**If only release-mode data is available for a given time, this notebook will:**\n",
    "1. Plot the time domain data, or a portion of the data \n",
    "2. Verify location of the pulses in the data and pulse length\n",
    "3. Plot the frequency spectrum and find the peaks \n",
    "4. Verify the beamforming if output_samples_iq is available\n",
    "\n",
    "**If debug-mode data is available (rawrf, txdata), this notebook will also:**\n",
    "1. Verify the rawrf from the txdata\n",
    "2. Find the peaks of the FFT in the rawrf data and compare to the bfiq data to verify the decimation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import deepdish\n",
    "import numpy as np\n",
    "import random\n",
    "sys.path.append('../testing_utils/plot_borealis_hdf5_data/')\n",
    "\n",
    "from test_beamforming import plot_bf_iq_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/data/borealis_data/20190206/20190206.2101.04.sas.0.bfiq.hdf5'\n",
    "data_file = os.path.basename(filename)\n",
    "data_directory = os.path.dirname(os.path.dirname(filename)) # get directory outside of the data (/data/borealis_data)\n",
    "\n",
    "record_name = None  # or change if you want a specific record "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Filetypes: \n",
      "0.bfiq\n",
      "0.output_samples_iq\n"
     ]
    }
   ],
   "source": [
    "# get the corresponding data files to this data file, including output_samples_iq, bfiq,\n",
    "# rawrf, txdata if available.\n",
    "\n",
    "data_file_metadata = data_file.split('.')\n",
    "\n",
    "date_of_file = data_file_metadata[0]\n",
    "timestamp_of_file = '.'.join(data_file_metadata[0:3])\n",
    "station_name = data_file_metadata[3]\n",
    "slice_id_number = data_file_metadata[4]\n",
    "type_of_file = data_file_metadata[-2]  # XX.hdf5\n",
    "if type_of_file == slice_id_number:\n",
    "    slice_id_number = '0'  # choose the first slice to search for other available files.\n",
    "else:\n",
    "    type_of_file = slice_id_number + '.' + type_of_file\n",
    "file_suffix = data_file_metadata[-1]\n",
    "\n",
    "if file_suffix != 'hdf5':\n",
    "    raise Exception('Incorrect File Suffix: {}'.format(file_suffix))\n",
    "\n",
    "output_samples_filetype = slice_id_number + \".output_samples_iq\"\n",
    "bfiq_filetype = slice_id_number + \".bfiq\"\n",
    "rawrf_filetype = \"rawrf\"\n",
    "tx_filetype = \"txdata\"\n",
    "file_types_avail = [bfiq_filetype, output_samples_filetype, tx_filetype, rawrf_filetype]\n",
    "\n",
    "if type_of_file not in file_types_avail:\n",
    "    raise Exception(\n",
    "        'Data type: {} not incorporated in script. Allowed types: {}'.format(type_of_file,\n",
    "                                                                             file_types_avail))\n",
    "\n",
    "data = {}\n",
    "print('Available Filetypes: ')\n",
    "for file_type in list(file_types_avail):  # copy of file_types_avail so we can modify it within.\n",
    "    try:\n",
    "        filename = data_directory + '/' + date_of_file + '/' + timestamp_of_file + \\\n",
    "                    '.' + station_name + '.' + file_type + '.hdf5'\n",
    "        data[file_type] = deepdish.io.load(filename)\n",
    "        print(file_type)\n",
    "    except:\n",
    "        file_types_avail.remove(file_type)\n",
    "        if file_type == type_of_file:  # if this is the filename you provided.\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record Name Chosen: 1549486913436\n"
     ]
    }
   ],
   "source": [
    "# Choose a record from the provided file, and get that record for each filetype to analyze side by side.\n",
    "# Also reshaping data to correct dimensions - if there is a problem with reshaping, we will also not use that record.\n",
    "\n",
    "good_record_found = False\n",
    "record_attempts = 0\n",
    "while not good_record_found:\n",
    "    if record_name is None:\n",
    "        record_name = random.choice(list(data[type_of_file].keys()))\n",
    "    print('Record Name Chosen: {}'.format(record_name))\n",
    "\n",
    "    record_data = {}\n",
    "\n",
    "    try:\n",
    "        for file_type in file_types_avail:\n",
    "            record_data[file_type] = data[file_type][record_name]\n",
    "\n",
    "            if file_type == bfiq_filetype:\n",
    "                bf_iq = record_data[bfiq_filetype]\n",
    "                number_of_beams = len(bf_iq['beam_azms'])\n",
    "                number_of_arrays = len(bf_iq['antenna_arrays_order'])\n",
    "                flat_data = np.array(bf_iq['data'])  \n",
    "                # reshape to 2 (main, intf) x nave x number_of_beams x number_of_samples\n",
    "                bf_iq_data = np.reshape(flat_data, (number_of_arrays, bf_iq['num_sequences'], number_of_beams, bf_iq['num_samps']))\n",
    "                bf_iq['data'] = bf_iq_data\n",
    "                beam_azms = bf_iq['beam_azms']\n",
    "                pulses = bf_iq['pulses']\n",
    "                decimated_rate = bf_iq['rx_sample_rate']\n",
    "                tau_spacing = bf_iq['tau_spacing']\n",
    "                freq = bf_iq['freq']\n",
    "                nave = bf_iq['num_sequences']\n",
    "                main_antenna_count = bf_iq['main_antenna_count']\n",
    "                intf_antenna_count = bf_iq['intf_antenna_count']\n",
    "\n",
    "            if file_type == output_samples_filetype:\n",
    "                output_samples_iq = record_data[output_samples_filetype]\n",
    "                number_of_antennas = len(output_samples_iq['antenna_arrays_order'])\n",
    "\n",
    "                flat_data = np.array(output_samples_iq['data'])  \n",
    "                # reshape to number of antennas (M0..... I3) x nave x number_of_samples\n",
    "                output_samples_iq_data = np.reshape(flat_data, (number_of_antennas, output_samples_iq['num_sequences'], output_samples_iq['num_samps']))\n",
    "                output_samples_iq['data'] = output_samples_iq_data\n",
    "                antennas_present = [int(i.split('_')[-1]) for i in output_samples_iq['antenna_arrays_order']]\n",
    "                output_samples_iq['antennas_present'] = antennas_present\n",
    "\n",
    "            if file_type == rawrf_filetype:\n",
    "                rawrf = record_data[rawrf_filetype]\n",
    "                number_of_antennas = rawrf['main_antenna_count'] + rawrf['intf_antenna_count']\n",
    "                #number_of_antennas = len(rawrf['antenna_arrays_order'])\n",
    "                flat_data = np.array(rawrf['data'])  \n",
    "                # reshape to num_sequences x number_of_antennas x number_of_samples\n",
    "                rawrf_data = np.reshape(flat_data, (rawrf['num_sequences'], number_of_antennas, rawrf['num_samps']))\n",
    "                rawrf['data'] = rawrf_data\n",
    "                rawrf['antennas_present'] = range(0,rawrf['main_antenna_count'] + rawrf['intf_antenna_count'])\n",
    "                # these are based on filter size. TODO test with modified filter sizes and\n",
    "                # build this based on filter size.\n",
    "\n",
    "                # determined by : 0.5 * filter_3_num_taps * dm_rate_1 * dm_rate_2 + 0.5 *\n",
    "                # filter_3_num_taps. First term is indicative of the number of samples\n",
    "                # that were added on so that we don't miss the first pulse, second term\n",
    "                # aligns the filter so that the largest part of it (centre) is over the pulse.\n",
    "\n",
    "                # This needs to be tested.\n",
    "                rawrf['dm_start_sample'] = 180*10*5 + 180\n",
    "\n",
    "            # tx data does not need to be reshaped.\n",
    "            if file_type == tx_filetype:\n",
    "                tx = record_data[tx_filetype]\n",
    "                tx['rx_sample_rate'] = tx['tx_rate'][0]/tx['dm_rate']\n",
    "                print('Decimation rate error: {}'.format(tx['dm_rate_error']))\n",
    "                print(tx['rx_sample_rate'])\n",
    "                tx['data_descriptors'] = ['num_sequences', 'num_antennas', 'num_samps']\n",
    "                tx['data'] = tx['decimated_tx_samples']\n",
    "                tx['antennas_present'] = tx['decimated_tx_antennas'][0]\n",
    "                tx['dm_start_sample'] = 0\n",
    "\n",
    "\n",
    "    except ValueError as e:\n",
    "        print('Record {} raised an exception in filetype {}:\\n'.format(record_name, file_type))\n",
    "        traceback.print_exc()\n",
    "        print('\\nA new record will be selected.')\n",
    "        record_attempts +=1\n",
    "        if record_attempts == 3:\n",
    "            print('FILES FAILED WITH 3 FAILED ATTEMPTS TO LOAD RECORDS.')\n",
    "            raise # something is wrong with the files \n",
    "    else:  # no errors\n",
    "        good_record_found = True\n",
    "\n",
    "if bfiq_filetype not in file_types_avail:\n",
    "    raise Exception('BFIQ data is required to do tests and could not be loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # find pulse points in data that is decimated. \n",
    "\n",
    "    #plot_output_samples_iq_data(record_data[output_samples_filetype], output_samples_filetype)\n",
    "    plot_bf_iq_data(record_data[bfiq_filetype], bfiq_filetype)\n",
    "    #plot_antenna_data(record_data[tx_filetype]['tx_samples'][0,:,:], record_data[tx_filetype]['tx_antennas'][0], tx_filetype, main_antenna_count)\n",
    "    #plot_antenna_data(record_data[output_samples_filetype]['data'][:,0,:], record_data[output_samples_filetype]['antenna_arrays_order'], output_samples_filetype, main_antenna_count, separate_plots=False)\n",
    "    #plot_antenna_data(record_data[rawrf_filetype]['data'][0,:,18000:20000], record_data[rawrf_filetype]['antennas_present'], rawrf_filetype, main_antenna_count,separate_plots=False)\n",
    "    #for antenna in range(0,record_data[tx_filetype]['tx_samples'].shape[1]):\n",
    "    #    fft_and_plot(record_data[tx_filetype]['tx_samples'][0,antenna,:], 5000000.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
