*******************
Borealis Data Files
*******************

Data Generation
---------------

The Borealis software module `data_write.py` is responsible for writing all data files.
Different flags can be given to the module to write various types of files. See the documentation for :ref:`Borealis Processes`

Borealis writes files into `HDF5 format <https://portal.hdfgroup.org/display/support>`_. Examples of how to use HDF5 files can
be found here for multiple languages: 
`HDF5 Examples <https://portal.hdfgroup.org/display/HDF5/HDF5+Examples>`_

The following data file types can be generated by Borealis in HDF5 format. The standard Borealis `release` mode run by the scheduler generates HDF5 files for rawacf, antennas_iq and bfiq.

**NOTE: Information in these pages requires a basic understanding of the HDF5 ecosystem.** See `This page <https://portal.hdfgroup.org/display/HDF5/Introduction+to+HDF5>`_ for basic information

..  toctree::
    :maxdepth: 2

    antennas_iq
    bfiq
    rawacf

Additionally, debugging file formats such as rawrf (non-filtered high bandwidth data) can be generated upon request. 

Reading Data
-------------

To read the files in python, we recommend using `PyTables <https://www.pytables.org/>`_ or `deepdish <https://deepdish.readthedocs.io/en/latest/index.html>`_ packages.


*************************
Data Storage and Deletion
*************************

Borealis file sizes can add up quickly to fill all available hard drive space, especially if antennas_iq and/or bfiq data types are being generated. However, it is convenient and recommended to keep a backlog of lower level data products such as antennas_iq for a period of time. These files are useful for debugging hardware issues and reproducing RAWACF files.

In order to prevent system failure due to hard drives filling up, a method for deleting the oldest data files is employed. This is referred to as `rotating` the files.

File Rotation
-------------

A utility script is scheduled via cron to check the filesystem that Borealis files are written to. If the filesystem usage is too high, it searches for and deletes the oldest files in a loop until the filesystem usage goes below the threshold. See the SuperDARN Canada `data flow repository <https://github.com/SuperDARNCanada/data_flow>`_ for more information.